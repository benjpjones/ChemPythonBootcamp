{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98015072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe349e",
   "metadata": {},
   "source": [
    "# Data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137b89c",
   "metadata": {},
   "source": [
    "Pandas is super versatile and can deal with a wide range of data formats. Usually though, a degree of data cleaning is needed to make it useable for a given application.  Consider the following spectrometer files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_excel(\"./RLM_07112022_fullantiangle18c6wBa.xlsx\",engine='openpyxl')\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1c42d",
   "metadata": {},
   "source": [
    "Theres a lot of badness here.  First, the bottom rows all seem to be trash. As is row 1.  We only want to read the first 600 or so rows which have the data in. Lets chop off all the garbage at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_excel(\"./RLM_07112022_fullantiangle18c6wBa.xlsx\",engine='openpyxl')[1:602]\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c6141",
   "metadata": {},
   "source": [
    "Now we've got to do something about the column names. Many pathologies are present here:\n",
    "1) The column names span two different rows; in Pandas the column names are not properly represented\n",
    "\n",
    "2) The actual name of the series is for some mysterious reason one column left of where the actual data for that series is.\n",
    "\n",
    "3) Wavelength occurs a totally unnecessary number of times, the same data for each series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets take care of 2 first. We need to rename each column of data with the name of the one that is placed one to the left of it.  \n",
    "#We'll also call the left-most column \"Wavelength\", and plan to kill all the other wavelength columns shortly\n",
    "\n",
    "\n",
    "#For this purpose we need a renaming mapper, a python dictionary that accepts the old column name and returns the new column name:\n",
    "\n",
    "renamemapper={}\n",
    "\n",
    "for i in range(0,len(dat.columns)-1):\n",
    "    renamemapper[dat.columns[i+1]]=dat.columns[i]\n",
    "renamemapper[dat.columns[0]]=\"Wavelength\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9aee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dictionary works like this - you query it with the old name and it gives you the new one\n",
    "\n",
    "renamemapper['Unnamed: 1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42665086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now destroy all the unnecessary columns. Wavelength occurs every even numbered column, \n",
    "# so these are the ones that need to die, in the existing labelling scheme:\n",
    "\n",
    "WhichOnesToKill=range(2,len(dat.columns),2)\n",
    "ToKill=dat.columns[WhichOnesToKill]\n",
    "print(ToKill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_trimmed=dat.drop(ToKill,axis=1)\n",
    "dat_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll apply the rename mapper:\n",
    "dat_renamed=dat_trimmed.rename(renamemapper,axis=1).astype(float)\n",
    "dat_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa2581",
   "metadata": {},
   "source": [
    "Getting there! Now, according to this column naming convention, the columns names really mean something. The format is:\n",
    "\n",
    "\"Name_anti[angle]\"\n",
    "\n",
    "We'd like to organize them into some data structure that reflects this organizing principle.  Maybe say, a dictionary where the key is the angle, and the value is the data series? Lets try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4073b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing we need to do is extract the actual angle from the column name string. \n",
    "# A typical column name is like this:\n",
    "examplename=dat_renamed.columns[1]\n",
    "print(examplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What can we do to get the number out?  Here are some options that don't work and one that does:\n",
    "#   1. Go through the string, and detect we are at at a number vs a letter, and keep the numbers.\n",
    "#      --> doesnt work because 18 and 6170 also appear\n",
    "#   2. Keep only the last 2 characters\n",
    "#      --> doesnt work because sometimes the angle is only one digit long\n",
    "#   3. Find an instance of \"anti\" and keep everythig right\n",
    "#      --> this works, as long as some inventive spectrometer inventor doesnt change the name convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09575d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"split\" command will divide a string based on instances of some substring. Like this:\n",
    "SomeString=\"a_walrus_b_walrus_c_walrus_d_walrus_e\"\n",
    "SomeString.split(\"_walrus_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can do this to split out the angle:\n",
    "examplename.split(\"anti\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18626fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But note the '' there, it is a string '85' whereas we want a number 85. Convert it to a float:\n",
    "float(examplename.split(\"anti\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a71552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OK, so with that solved, lets fill up our new data structure, indexed by the angle:\n",
    "AntiAngleDict={}\n",
    "ColumnNames=dat_renamed.columns\n",
    "for name in ColumnNames:\n",
    "    if \"anti\" in name:\n",
    "        angle = float(name.split(\"anti\")[-1])\n",
    "        AntiAngleDict[angle]=np.array(dat_renamed[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract from this structure the response at each angle\n",
    "AntiAngleDict[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(AntiAngleDict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99655b3e",
   "metadata": {},
   "source": [
    "# Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for some plots. We want to plot each angle one by one. First get a sorted list of angles \n",
    "# that are in the data structure:\n",
    "angles=np.sort(list(AntiAngleDict.keys()))\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use a nice color map that is reddest at the max angle and bluest at the min angle.\n",
    "# Python color maps are by default indexed from 0 to 1. So we'll make a dictionary saying what\n",
    "#   color to use for each angle:\n",
    "colors={}\n",
    "\n",
    "# Jet is a \"rainbow\" type color map in python. \n",
    "jet =  pylab.get_cmap('jet') \n",
    "\n",
    "for angle in angles:\n",
    "    colors[angle]=jet(angle/max(angles))\n",
    "\n",
    "# This is the RGBK index to the color for that angle\n",
    "colors[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make a plot:\n",
    "\n",
    "pylab.figure(figsize=(5,5),dpi=200)\n",
    "\n",
    "for angle in angles:\n",
    "    pylab.plot(dat_renamed.Wavelength, AntiAngleDict[angle],color=colors[angle],label=round(angle))\n",
    "\n",
    "pylab.legend(loc='upper right') \n",
    "pylab.xlabel(\"Wavelength (nm)\")\n",
    "pylab.ylabel(\"Fluorescene Intensity (arb)\")\n",
    "pylab.ylim(0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e558ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use our scattering normalization trick, we need to know which rows \n",
    "# have wavelength in the interesting range. Thats these:\n",
    "\n",
    "normframe=dat_renamed.loc[(200<dat_renamed.Wavelength) & (400>dat_renamed.Wavelength)]\n",
    "\n",
    "normframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing each column gives the normalization constant:\n",
    "\n",
    "normsums= normframe.sum()\n",
    "normsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do the angle thing again:\n",
    "NormalizationDict={}\n",
    "ColumnNames=dat_renamed.columns\n",
    "for name in ColumnNames:\n",
    "    if \"anti\" in name:\n",
    "        angle = float(name.split(\"anti\")[-1])\n",
    "        NormalizationDict[angle]=float(normsums[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5563b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make the normalized plot:\n",
    "\n",
    "pylab.figure(figsize=(5,5),dpi=200)\n",
    "\n",
    "for angle in angles:\n",
    "    pylab.plot(dat_renamed.Wavelength, AntiAngleDict[angle]/NormalizationDict[angle],color=colors[angle],label=round(angle))\n",
    "\n",
    "pylab.legend(loc='upper right') \n",
    "pylab.xlabel(\"Wavelength (nm)\")\n",
    "pylab.ylabel(\"Fluorescene Intensity (arb)\")\n",
    "pylab.ylim(0,0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c3af7",
   "metadata": {},
   "source": [
    "# Condensing the hard work into portable functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1434c",
   "metadata": {},
   "source": [
    "Once we've figured out the recipe, we can put all that into a function so we don't need a million rows of notebook every time we want a new plot. The following two functions condense down the process of reading the file and making the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadFile(filename,toprange=602):\n",
    "\n",
    "    AntiAngleDict={}  \n",
    "    NormDict={}\n",
    "    \n",
    "    dat=pd.read_excel(filename,engine='openpyxl')[1:toprange]\n",
    "\n",
    "    renamemapper={}\n",
    "    for i in range(0,len(dat.columns)-1):\n",
    "        renamemapper[dat.columns[i+1]]=dat.columns[i]\n",
    "    renamemapper[dat.columns[0]]=\"Wavelength\"\n",
    "    dat= dat.rename(renamemapper,axis=1).astype(float)\n",
    "    dat= dat.drop(dat.columns[range(2,len(dat.columns),2)],axis=1)\n",
    "    \n",
    "    dat_norm=dat.loc[(200<dat.Wavelength) & (400>dat.Wavelength)]\n",
    "    \n",
    "    for name in dat.columns:\n",
    "        if(\"anti\" in name):\n",
    "            angle = float(name.split(\"anti\")[-1])\n",
    "            AntiAngleDict[angle]=np.array(dat[name])\n",
    "            NormDict[angle]=float(dat_norm.sum()[name])\n",
    "\n",
    "    return dat, AntiAngleDict, NormDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePlot(dat, AntiAngleDict, NormDict):\n",
    "    pylab.figure(figsize=(5,5),dpi=200)\n",
    "    angles=np.sort(list(AntiAngleDict.keys()))\n",
    "    jet=pylab.get_cmap(\"jet\")\n",
    "    for angle in angles:\n",
    "        col=jet(angle/max(angles))\n",
    "        pylab.plot(dat.Wavelength, AntiAngleDict[angle]/NormDict[angle],color=col,label=round(angle))\n",
    "            \n",
    "    pylab.legend(loc='upper right') \n",
    "    pylab.xlabel(\"Wavelength (nm)\")\n",
    "    pylab.ylabel(\"Fluorescene Intensity (arb)\")\n",
    "    pylab.ylim(0,0.05)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "dat_vaptes, aa_vaptes, nd_vaptes=ReadFile(\"./RLM_07112022_fullantiangleVAPTES.xlsx\")\n",
    "dat_18c6Ba, aa_18c6Ba, nd_18c6Ba=ReadFile(\"./RLM_07112022_fullantiangle18c6wBa.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e93729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the original plot\n",
    "MakePlot(dat_vaptes, aa_vaptes, nd_vaptes)\n",
    "MakePlot(dat_18c6Ba, aa_18c6Ba, nd_18c6Ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "\n",
    "# plot the scattering-normalized response of piranha glass, VAPTES, 18c6, 18c6+Ba at \n",
    "# anti35 degrees, using the files included in this github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7d291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
